{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948b4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffe56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b38d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f007b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a15a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = data.get_word_index() \n",
    "\n",
    "word_index = {k:(v+3) for k, v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0 \n",
    "word_index[\"<START>\"] = 1 \n",
    "word_index[\"<UNK>\"] = 2 \n",
    "word_index[\"<UNUSED>\"] = 3 \n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3495cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad4f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d4f31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(decode_review(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4e0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dee3778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(X,E):\n",
    "    return np.array([E[i] for i in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f3ad7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(X):\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "255adc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    E = np.random.randn(vocab_size, embedding_dim)\n",
    "    W1 = np.random.randn(16,16)\n",
    "    b1 = np.random.randn(16,)\n",
    "    W2 = np.random.randn(16,1)\n",
    "    b2 = np.random.randn(1,)\n",
    "    return E, W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1da8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(E, W1, b1, W2, b2, X):\n",
    "    Z0 = embed(X,E)\n",
    "    A1 = Z0\n",
    "    Z1 = np.mean(A1, axis=0)\n",
    "    A2 = Z1\n",
    "    Z2 = A2.dot(W1) + b1\n",
    "    A3 = ReLU(Z2)\n",
    "    Z3 = A3.dot(W2) + b2\n",
    "    A4 = sigmoid(Z3)\n",
    "    return A1, A2, Z2, A3, Z3, A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce98372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(A1, A2, Z2, A3, A4, Y, E, W1, W2, X):\n",
    "    m=Y.size\n",
    "    dZ3 = (A4 - Y)/m\n",
    "    dW2 = A3.reshape(-1, 1) * dZ3\n",
    "    db2 = dZ3.flatten()\n",
    "\n",
    "    dA3 = dZ3 * W2.flatten()\n",
    "    dZ2 = dA3 * (Z2 > 0)\n",
    "    dW1 = A2.reshape(-1, 1).dot(dZ2.reshape(1, -1))\n",
    "    db1 = dZ2.flatten()\n",
    "\n",
    "    dA2 = dZ2.dot(W1.T)\n",
    "    dZ1 = dA2 / A1.shape[0]\n",
    "    dA1 = np.tile(dZ1, (A1.shape[0], 1))\n",
    "\n",
    "    dE = np.zeros_like(E)\n",
    "    for t, tok in enumerate(X):\n",
    "        dE[tok] += dA1[t]\n",
    "    \n",
    "    return dE, dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eacaf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(E, W1, b1, W2, b2, dE, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    E  = E - learning_rate * dE\n",
    "    return E, W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "595982ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A4):\n",
    "    return np.argmax(A4, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions==Y)/Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ea792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, iterations, learning_rate):\n",
    "    E, W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        correct = 0\n",
    "        for j in range(len(X)):\n",
    "            A1, A2, Z2, A3, Z3, A4 = forward_prop(E, W1, b1, W2, b2, X[j])\n",
    "            dE, dW1, db1, dW2, db2 = back_prop(A1, A2, Z2, A3, A4, Y[j], E, W1, W2, X[j])\n",
    "            E, W1, b1, W2, b2 = update_params(E, W1, b1, W2, b2, dE, dW1, db1, dW2, db2, learning_rate)\n",
    "\n",
    "            prediction = 1 if A4[0] > 0.5 else 0\n",
    "            if prediction == Y[j]:\n",
    "                correct += 1\n",
    "                \n",
    "        if i % 10 == 0:\n",
    "            accuracy = correct / len(X)\n",
    "            print(\"Iteration:\", i, \"Accuracy: \", accuracy)\n",
    "    return E, W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11f5cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Accuracy:  0.56052\n",
      "Iteration: 10 Accuracy:  0.75048\n",
      "Iteration: 10 Accuracy:  0.75048\n",
      "Iteration: 20 Accuracy:  0.7992\n",
      "Iteration: 20 Accuracy:  0.7992\n",
      "Iteration: 30 Accuracy:  0.82392\n",
      "Iteration: 30 Accuracy:  0.82392\n",
      "Iteration: 40 Accuracy:  0.8396\n",
      "Iteration: 40 Accuracy:  0.8396\n",
      "Iteration: 50 Accuracy:  0.85136\n",
      "Iteration: 50 Accuracy:  0.85136\n",
      "Iteration: 60 Accuracy:  0.85968\n",
      "Iteration: 60 Accuracy:  0.85968\n",
      "Iteration: 70 Accuracy:  0.86908\n",
      "Iteration: 70 Accuracy:  0.86908\n",
      "Iteration: 80 Accuracy:  0.87464\n",
      "Iteration: 80 Accuracy:  0.87464\n",
      "Iteration: 90 Accuracy:  0.8812\n",
      "Iteration: 90 Accuracy:  0.8812\n"
     ]
    }
   ],
   "source": [
    "\n",
    "E, W1, b1, W2, b2 = gradient_descent(train_data, train_labels, 100, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "78a34d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(E, W1, b1, W2, b2, X_test, Y_test):\n",
    "    correct = 0\n",
    "    for i in range(len(X_test)):\n",
    "        A1, A2, Z2, A3, Z3, A4 = forward_prop(E, W1, b1, W2, b2, X_test[i])\n",
    "        prediction = 1 if A4[0] > 0.5 else 0\n",
    "        if prediction == Y_test[i]:\n",
    "            correct += 1\n",
    "        if prediction == 0:\n",
    "            print(A4[0])\n",
    "            print(i)\n",
    "            break\n",
    "    \n",
    "    accuracy = correct / len(X_test)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bd24edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3082849029847548\n",
      "7\n",
      "Test Accuracy: 0.0002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00024"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(E, W1, b1, W2, b2, test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aa3b6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(E, W1, b1, W2, b2, test_text, i):\n",
    "    A1, A2, Z2, A3, Z3, A4 = forward_prop(E, W1, b1, W2, b2, test_data[i])\n",
    "    prediction = 1 if A4[0] > 0.5 else 0\n",
    "    if(prediction==1):\n",
    "        print(\"positive\")\n",
    "    else:\n",
    "        print(\"negative\")    \n",
    "    print(A4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c603c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 0, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 0, 19, 861, 1074, 5, 1987, 0, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 0, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 0, 5, 4182, 30, 3127, 0, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 0, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]\n",
      "[0, 591, 202, 14, 31, 6, 717, 10, 10, 0, 0, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 0, 38, 32, 25, 7944, 451, 202, 14, 6, 717, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def text_to_ids(sentence, word_index, unk_id=0):\n",
    "    words = sentence.lower().split()\n",
    "    ids = [word_index.get(w, unk_id) for w in words]\n",
    "    return ids\n",
    "p_sentence = \"focuses on mood and character development the plot is very simple and many of the scenes take place on the same set in frances <UNK> the sandy dennis character apartment but the film builds to a disturbing climax br br the characters create an atmosphere <UNK> with sexual tension and psychological <UNK> it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the brilliant performance by sandy dennis it's definitely one of her darker characters but she plays it so perfectly and convincingly that it's scary michael burns does a good job as the mute young man regular altman player michael murphy has a small part the <UNK> moody set fits the content of the story very well in short this movie is a powerful study of loneliness sexual <UNK> and desperation be patient <UNK> up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to <UNK> a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\"#\"This movie straight-up crawled under my skin in the softest way possible, like a ghost giving me a weighted blanket hug üò≠‚ú® The whole vibe felt dreamlike but not in that confusing ‚Äúwhat is happening‚Äù way‚Äîmore like drifting through a memory you forgot you loved. Every frame looked handcrafted, like the director dipped their fingers into the screen and rearranged reality just for fun. The acting? Bro‚Ä¶ unreal. The lead carried this quiet storm energy that made every tiny expression hit like a prophecy. Even when nobody was talking, the silence felt alive, slithering around the edges like it knew secrets it refused to share. The score wrapped around the story like a heartbeat‚Äîsteady, comforting, but always a little off-kilter, reminding you something bigger was coming. And when the emotional punch finally landed in the final act? I swear my soul did a somersault. It‚Äôs the kind of film that follows you home, sits in your room, and whispers, ‚Äúthink about me.‚Äù And I do. I will. Forever. 10/10, honestly felt like being gently haunted by beauty.\"\n",
    "n_sentence = \"<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"#\"Man‚Ä¶ this movie cooked me emotionally but not in a good way üíÄ Like, it tried so desperately to feel profound that it ended up chasing its own shadow for two hours. Every scene dragged itself across the floor, begging to matter, but never getting there. The dialogue felt like someone fed an AI a motivational poster and said ‚Äúmake it deep.‚Äù Characters wandered around like NPCs who forgot their quest lines. Nothing they said or did connected to anything. The story kept hinting at meaning, but every reveal landed flatter than a broken jump scare. I swear the plot twists were so predictable I called one while half-asleep scrolling my phone. The soundtrack was dramatic for no reason‚Äîviolins screaming while someone boiled pasta or stared at a lamp like it held the secrets of the universe. Bro, I was fighting for my life trying not to laugh. By the end, I felt like the movie siphoned my energy, my patience, and maybe part of my lifespan. 2/10, only because the credits rolled and freed me.\"\n",
    "p_array = text_to_ids(p_sentence, word_index)\n",
    "n_array = text_to_ids(n_sentence, word_index)\n",
    "print(p_array) \n",
    "print(n_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "959c660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=[\n",
    "    [1,13,784,14,20, 2 ,12,9,38,357],\n",
    "    [1,13,66,423,12],\n",
    "    [1,13,1539,18,164, 2 ,87],\n",
    "    [1,118, 20, 126],\n",
    "    [1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 0, 38, 32, 25, 7944, 451, 202, 14, 6, 717, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 2, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 2, 5, 4182, 30, 3127, 0, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077],\n",
    "    [   1,    4,    2,  745,    2,  912,    9,    2,    8,    2, 1820, 5889,  912,  190,   54,    2, 8408, 7024, 2957,   11,  513,    8, 2225,    6, 1853, 1799,    8,    4, 5110,   27,  912,    9, 2982,   34,    2,  912,  103,    6, 1060, 1274,  121,    2,    9,    2,   39,  513,    6,    2, 5692,   15,    2,  912,  215, 6275,  912,   38,   15,   59,   70, 3083,   41,    2, 3564,   14,    9, 6749,    5,    4, 2515,  809,   11,  119,   38,   81,    2,    5,    2,    4,  360,    7,    4,   22, 4097,   34,   19,  883,    5,   33,    4,  130,    2,  912,  408, 2540,   21,   37,    9,    4,  336,   10,   10,    4,  912,   65,    9,    4,   55,  815, 2196,   15,    9,  343,    8,  353,    5,  987,    6,   65,  200, 1714,   94,    6,  394,  769,   50,   26,  342,  293,  621, 1328,   32,    7,   63,   26, 1916,   78,  690,    5, 2150, 3822,   94,   43,   35,  576,  357,   22, 8408,   47,   99,  111,  715,   11,  257, 4130,    5, 1545,   98,   11,   35,  220, 2227, 1377,   94,   24,  163,  126,   21,   94,  981,    8,   30, 8408,    5, 1820,   28,  224,   76,  128,   74,   14,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]\n",
    "#test_text=np.array([a + [0]*(250 - len(a)) for a in test_text])\n",
    "y_test = [0, 1, 0, 1, 0, 1]\n",
    "#print(test_text[4])\n",
    "#print(decode_review(test_text[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "941feea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "0.5879252373516386\n",
      "[   1    4    2  745    2  912    9    2    8    2 1820 5889  912  190\n",
      "   54    2 8408 7024 2957   11  513    8 2225    6 1853 1799    8    4\n",
      " 5110   27  912    9 2982   34    2  912  103    6 1060 1274  121    2\n",
      "    9    2   39  513    6    2 5692   15    2  912  215 6275  912   38\n",
      "   15   59   70 3083   41    2 3564   14    9 6749    5    4 2515  809\n",
      "   11  119   38   81    2    5    2    4  360    7    4   22 4097   34\n",
      "   19  883    5   33    4  130    2  912  408 2540   21   37    9    4\n",
      "  336   10   10    4  912   65    9    4   55  815 2196   15    9  343\n",
      "    8  353    5  987    6   65  200 1714   94    6  394  769   50   26\n",
      "  342  293  621 1328   32    7   63   26 1916   78  690    5 2150 3822\n",
      "   94   43   35  576  357   22 8408   47   99  111  715   11  257 4130\n",
      "    5 1545   98   11   35  220 2227 1377   94   24  163  126   21   94\n",
      "  981    8   30 8408    5 1820   28  224   76  128   74   14    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[   1    4    2  745    2  912    9    2    8    2 1820 5889  912  190\n",
      "   54    2 8408 7024 2957   11  513    8 2225    6 1853 1799    8    4\n",
      " 5110   27  912    9 2982   34    2  912  103    6 1060 1274  121    2\n",
      "    9    2   39  513    6    2 5692   15    2  912  215 6275  912   38\n",
      "   15   59   70 3083   41    2 3564   14    9 6749    5    4 2515  809\n",
      "   11  119   38   81    2    5    2    4  360    7    4   22 4097   34\n",
      "   19  883    5   33    4  130    2  912  408 2540   21   37    9    4\n",
      "  336   10   10    4  912   65    9    4   55  815 2196   15    9  343\n",
      "    8  353    5  987    6   65  200 1714   94    6  394  769   50   26\n",
      "  342  293  621 1328   32    7   63   26 1916   78  690    5 2150 3822\n",
      "   94   43   35  576  357   22 8408   47   99  111  715   11  257 4130\n",
      "    5 1545   98   11   35  220 2227 1377   94   24  163  126   21   94\n",
      "  981    8   30 8408    5 1820   28  224   76  128   74   14    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "testing(E, W1, b1, W2, b2, test_text, 6)\n",
    "print(np.array(test_text[6]))\n",
    "print(test_data[7])\n",
    "#test_model(E, W1, b1, W2, b2, test_text, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f66f00d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> the <UNK> richard <UNK> dog is <UNK> to <UNK> joan fontaine dog however when <UNK> bing crosby arrives in town to sell a record player to the emperor his dog is attacked by <UNK> dog after a revenge attack where <UNK> is <UNK> from town a <UNK> insists that <UNK> dog must confront dog so that she can overcome her <UNK> fears this is arranged and the dogs fall in love so do <UNK> and <UNK> the rest of the film passes by with romance and at the end <UNK> dog gives birth but who is the father br br the dog story is the very weak vehicle that is used to try and create a story between humans its a terrible storyline there are 3 main musical pieces all of which are rubbish bad songs and dreadful choreography its just an extremely boring film bing has too many words in each sentence and delivers them in an almost irritating manner its not funny ever but its meant to be bing and joan have done much better than this <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "print(decode_review(test_text[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "25fb94dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> the <UNK> richard <UNK> dog is <UNK> to <UNK> joan fontaine dog however when <UNK> bing crosby arrives in town to sell a record player to the emperor his dog is attacked by <UNK> dog after a revenge attack where <UNK> is <UNK> from town a <UNK> insists that <UNK> dog must confront dog so that she can overcome her <UNK> fears this is arranged and the dogs fall in love so do <UNK> and <UNK> the rest of the film passes by with romance and at the end <UNK> dog gives birth but who is the father br br the dog story is the very weak vehicle that is used to try and create a story between humans its a terrible storyline there are 3 main musical pieces all of which are rubbish bad songs and dreadful choreography its just an extremely boring film bing has too many words in each sentence and delivers them in an almost irritating manner its not funny ever but its meant to be bing and joan have done much better than this <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "i=7\n",
    "print(decode_review(test_data[i]))\n",
    "print(test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f8b5b2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:  [[ 0.07509268 -0.21391617 -0.03601754 ... -0.01147904  0.49341896\n",
      "  -0.00853286]\n",
      " [-0.2465896  -0.12930816  0.50363968 ... -0.60155447 -2.27323984\n",
      "  -0.5965225 ]\n",
      " [ 0.9155115   0.6678291   0.51701345 ... -0.27287972  0.52690106\n",
      "  -1.19417843]\n",
      " ...\n",
      " [ 0.03890993 -0.14127242 -1.6207738  ... -0.24703842 -2.0588844\n",
      "  -0.55662718]\n",
      " [ 2.17807355  0.82876638  0.74720959 ... -1.2772134   1.30240427\n",
      "  -0.71623748]\n",
      " [ 0.15765434 -0.38588308  0.39095317 ...  1.48876608  0.59307307\n",
      "  -0.07973281]]\n",
      "W1:  [[-3.82990183e-01 -1.15133608e+00  2.71973946e+00 -1.48713060e+00\n",
      "  -1.03335065e+00 -1.54211966e+00 -3.87914614e-01  1.15709145e+00\n",
      "  -2.25065353e+00 -1.04185128e+00 -1.45163154e+00  1.53575655e+00\n",
      "   1.59395131e-02 -1.92718732e-01  1.96111696e+00 -2.62865262e-01]\n",
      " [-8.93844599e-01 -1.79663788e+00 -2.28197916e+00  1.03414458e+00\n",
      "  -8.92284970e-05  9.74888135e-02  6.41392069e-01  8.25961700e-01\n",
      "   2.26807922e+00  4.95560924e-01  1.66579509e-02  1.14290000e+00\n",
      "   7.86936810e-01  6.98335208e-01 -2.19413710e+00 -1.55236008e-01]\n",
      " [-1.54026197e+00 -4.07226774e-01  1.59372859e-01 -1.08759491e+00\n",
      "   6.35391127e-01  4.70719080e-01 -4.08990946e-02  1.92008312e+00\n",
      "  -5.17785846e-01 -8.69568351e-01  1.33238218e+00 -8.11882158e-01\n",
      "   3.29315121e-01  5.65575667e-01 -2.02762617e+00  1.67507315e-01]\n",
      " [-1.24150397e+00 -8.68488176e-01 -5.81261734e-01  9.05487510e-01\n",
      "   6.64492433e-01  6.16041633e-01 -4.67858933e-01 -1.27127962e+00\n",
      "   4.75886713e-01  2.02785749e-01 -3.53514107e-01 -6.23896215e-01\n",
      "  -3.43499226e+00  8.35424929e-01 -3.01432121e-01 -5.27645426e-01]\n",
      " [ 2.74139078e-01 -6.69386528e-04 -2.88594447e+00 -2.89191426e+00\n",
      "  -6.41130254e-01  2.43902430e+00 -9.37696891e-01 -2.17027621e-01\n",
      "   3.87369082e+00 -3.12995974e-01  2.07261377e-01 -4.47199024e-01\n",
      "  -4.90360699e-01  3.15369198e-01 -1.58482986e+00 -2.03522850e-02]\n",
      " [ 2.63042523e-01  2.93877259e+00  2.54957947e+00  3.36913555e+00\n",
      "  -2.89236341e+00 -1.29323039e+00  7.24616523e-01 -5.19858373e-02\n",
      "  -3.71951157e+00 -3.26570937e-01 -1.02424389e+00  2.78072870e+00\n",
      "   1.50315865e-02  5.56165060e-01  1.38062370e+00  1.14157363e+00]\n",
      " [ 8.85496974e-01  8.30473777e-01  5.07966016e-01 -1.17816823e+00\n",
      "   1.78917059e+00 -6.03867417e-01 -1.61174519e-01  3.22002173e-02\n",
      "  -2.24317952e-01  1.29122849e+00 -6.76869080e-02 -8.01727391e-02\n",
      "  -1.92685685e-02  1.60573767e-01 -2.59221991e+00  7.42394696e-01]\n",
      " [-1.18409951e+00  9.54117667e-03 -2.63528715e+00 -2.71550309e+00\n",
      "   2.28716952e+00  1.10429651e+00  1.93865062e-01  5.60394601e-01\n",
      "   1.21694164e+00 -6.67694675e-01  2.85948066e-01  3.33972330e-01\n",
      "  -3.05468914e-01 -1.27956900e+00  8.24787891e-01 -8.54768411e-02]\n",
      " [-5.58333710e-01 -1.63722421e-01 -2.09831640e+00 -1.14003983e+00\n",
      "   1.93166265e+00 -3.55864043e-01 -2.36143653e-01 -6.97524471e-01\n",
      "   2.11796381e+00  2.23487534e-01  3.14714977e-01 -5.38482654e-01\n",
      "   1.72304558e+00 -2.52984011e+00 -7.59211082e-01  5.33637346e-01]\n",
      " [-1.32632948e+00  1.85699698e+00 -8.03131722e-01 -7.93283642e-01\n",
      "   1.06745026e+00  1.72511196e+00 -1.59945784e-01 -8.03832031e-01\n",
      "  -1.49283403e+00 -1.47322537e+00  8.34349879e-01  8.42209249e-01\n",
      "   2.25581812e+00 -8.03969604e-01  1.01065298e+00 -4.87319914e-01]\n",
      " [ 6.44578350e-01  9.12041046e-02 -2.28794036e+00 -3.63748748e+00\n",
      "   2.64078809e+00  1.64858795e-01 -9.44221379e-01 -1.44155940e+00\n",
      "   2.48006756e-01  6.60221554e-01  7.23668040e-01 -1.05333309e+00\n",
      "  -8.28783154e-01 -1.37842149e+00  5.00899923e-01  1.31059546e+00]\n",
      " [ 1.62669564e+00 -1.29498573e+00 -1.45111562e-01  1.00807003e+00\n",
      "   6.35536078e-01  1.67078893e+00  9.52251937e-01  1.16868844e+00\n",
      "  -8.18625669e-02 -7.26024740e-02  5.17193598e-01 -2.66928312e+00\n",
      "  -1.08479894e+00 -1.92413967e-02  6.70829023e-01 -1.01987035e+00]\n",
      " [ 8.73990799e-01 -8.23043027e-01 -1.92413262e-01 -1.29135983e+00\n",
      "   1.02842184e+00  7.42586898e-01 -1.23092558e+00 -4.72207487e-01\n",
      "   9.33404798e-01 -2.40437264e+00 -5.20479458e-01 -1.76529459e+00\n",
      "   2.67444358e+00 -1.03349989e+00 -1.10441362e+00 -1.80597922e+00]\n",
      " [ 1.10226823e+00 -1.62365586e+00  1.34263684e-01 -8.72606300e-01\n",
      "   1.47570514e+00  4.38899862e-01 -5.04973739e-01 -1.14062856e+00\n",
      "   1.61945064e+00 -8.03913097e-01  1.21169589e+00  1.12818252e-01\n",
      "  -1.90150632e+00  5.10837575e-01 -6.96287582e-02  1.41671923e-01]\n",
      " [-1.35075015e+00  1.03760530e+00  1.81434204e+00 -2.13880674e-01\n",
      "  -8.17101858e-01 -1.16720306e+00  9.14033141e-01 -1.11069922e+00\n",
      "  -1.32504739e+00 -1.80768605e+00 -1.68285927e-01 -1.37624755e+00\n",
      "  -1.08312815e+00 -2.53797743e-01  4.52721961e-01 -2.82716993e-01]\n",
      " [ 1.21186275e-01  1.56338714e-01  2.13988763e-01  7.82067849e-01\n",
      "  -1.27457031e-01  2.51389928e-01  7.38955293e-01 -1.00033112e+00\n",
      "  -6.31286652e-01 -8.35748800e-01 -1.06748916e-01  9.35494296e-01\n",
      "  -1.02638430e+00  5.23973984e-01  6.61988891e-01 -9.07539042e-01]]\n",
      "b1:  [-1.92251942 -0.20555153 -0.14183206 -0.12358937  0.40350778  0.44538229\n",
      " -1.09474546  0.06985951  0.68105311  0.08611544 -0.33613123  1.0762484\n",
      " -0.27371649 -0.13407761 -0.05599022 -2.25198029]\n",
      "W2:  [[-0.51924436]\n",
      " [ 2.26041328]\n",
      " [ 1.35003355]\n",
      " [ 1.25550691]\n",
      " [-1.07901332]\n",
      " [-0.84399244]\n",
      " [ 2.34284472]\n",
      " [ 1.01805264]\n",
      " [-1.29349979]\n",
      " [-0.99044069]\n",
      " [ 0.9104813 ]\n",
      " [ 0.98421686]\n",
      " [ 1.99909685]\n",
      " [ 0.89957205]\n",
      " [ 1.39653537]\n",
      " [-0.14622262]]\n",
      "b2:  [-1.08372944]\n"
     ]
    }
   ],
   "source": [
    "print(\"E: \", E)\n",
    "print(\"W1: \", W1)\n",
    "print(\"b1: \", b1)\n",
    "print(\"W2: \", W2)\n",
    "print(\"b2: \", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "39261d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"my_model.npz\",\n",
    "         E=E,\n",
    "         W1=W1,\n",
    "         b1=b1,\n",
    "         W2=W2,\n",
    "         b2=b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
